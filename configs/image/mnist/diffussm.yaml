# Configuration file for DDPM with a transformer backbone, from the paper
# "Scalable Diffusion Models with Transformers" (https://arxiv.org/abs/2212.09748)
diffusion:
  parameterization: "epsilon"
  # Sampling section determines the size of the sampled output
  # from the model, and defines the sampling method used
  sampling:
    output_channels: 1
    output_spatial_size: 32
    target: xdiffusion.samplers.ancestral.AncestralSampler
    params: {}
  # The noise scheduler to use with the forward diffusion process.
  noise_scheduler:
    target: xdiffusion.scheduler.DiscreteNoiseScheduler
    params:
      # The number of noise scales
      num_scales: 1000
      # The schedule type
      schedule_type: "linear"
      # Loss type to use for noise prediction.
      loss_type: "l2"
      importance_sampler:
        target: xdiffusion.importance_sampling.UniformSampler
        params:
          num_timesteps: 1000
  # A preprocessor to use with the context before sending to the score network.
  context_preprocessing:
      # No context to preprocess for this model
      - target: xdiffusion.context.IgnoreContextAdapter
        params: {}
  # A preprocessor for input to the model.
  input_preprocessing:
    target: xdiffusion.context.IgnoreInputPreprocessor
    params: {}
  # Setting for classifier free guidance.
  classifier_free_guidance:
    # Classifier-free guidance scale, where the value is >= 1.0
    classifier_free_guidance: 1.0
    # Unconditional guidance probability
    unconditional_guidance_probability: 0.2
    # The context signals to apply guidance to.
    signals: ["classes"]
    # For classifier free guidance, we need the ability to create an unconditional
    # context given the conditional context. This unconditional context needs
    # to be applied in both training and sampling, and will return a new
    # context dictionary given the original context dictionary.
    unconditional_context:
      target: xdiffusion.context.UnconditionalClassesAdapter
      params:
        num_classes: 10
  dynamic_thresholding:
    enable: True
    p: 0.99
    c: 1.7
  # Defines the score network for predicting the noise parameter
  score_network:
    target: xdiffusion.score_networks.diffussm.DiffusionSSM
    params:
      n_layers: 12
      d_model: 256 # Dimensionality of each token
      d_input: 1 # Number of input channels
      input_width: 32
      input_height: 32
      M: 2 # M = L / J - the upscale downscale ratio

      residual_config:
        target: xdiffusion.layers.residual.Residual
        params: {}

      block_config:
        target: xdiffusion.layers.sequence.SequenceResidualBlock
        params:
          bidirectional: True
          prenorm: true
          transposed: False
          dropout: 0.0
          tie_dropout: False
          # Pooling config
          pool_config:
            target: xdiffusion.layers.pool.DownAvgPool
            stride: 1
          # Normalization config
          norm_config: layer
          # SSM block implementation
          layer_config:
            target: xdiffusion.layers.s4d.S4D
            params:
              d_state: 64
              dropout: 0.0
              dt_min: 0.001
              dt_max: 0.1
              lr: 0.001
              transposed: False

# Describes the dataset used in training.
data:
  # Spatial width/height of the data input to the model.
  image_size: 32
  # Number of channels in the input data
  num_channels: 1
  # The number of classes in the dataset
  num_classes: 10
# Optional optimizer specification
optimizer:
  target: torch.optim.Adam
  params:
    lr: .0002
    betas: [0.9, 0.99]
